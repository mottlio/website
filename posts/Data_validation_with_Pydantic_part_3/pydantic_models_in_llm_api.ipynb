{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5760efdc",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Pydantic models in LLM API calls - Part 3\"\n",
    "subtitle: \"Exploring the use of Pydantic models directly in LLM API calls and with the Instructor library\"\n",
    "date: '2025-03-04'\n",
    "categories: ['Python', 'Pydantic', 'Data Validation', 'LLMs']\n",
    "format:\n",
    "  html:\n",
    "    code-fold: true\n",
    "    code-summary: \"Show code\"\n",
    "    code-tools: true\n",
    "    panel: tabset\n",
    "    renderings: dark\n",
    "    comments:\n",
    "      utterances:\n",
    "        repo: mottlio/using_pydantic_with_llms\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d81e9cc",
   "metadata": {},
   "source": [
    "# Passing the Pydantic model directly in the API call to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e56a479",
   "metadata": {},
   "source": [
    "In this article I'll try to use Pydantic in the API calls to LLM experimenting with OpenAIs beta API and the Instructor package. The way Pydantic works with [Instructor](https://python.useinstructor.com/) is described in detail [here](https://pydantic.dev/articles/llm-intro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eef1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "|# code-summary: \"Import all required libraries\"\n",
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "# instructor is a library for extracting structured data from Large Language Models (LLMs). It is built on top of Pydantic.\n",
    "# instructor extracts the JSON schema from a Pydantic model and passes it in the prompt. It handles retries and parsing of the response.\n",
    "# Instructor takes a 'response_model' parameter in the API call, which is a Pydantic model that defines the structure of the expected response.\n",
    "import instructor\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: \"Define Pydantic models for customer support queries\"\n",
    "# Define the UserInput model for customer support queries\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        # Default value is None\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        #Greater or equal to 10000 and less than or equal to 99999\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None\n",
    "\n",
    "# Define the CustomerQuery model that inherits from UserInput. It adds fields that will be populated by the LLM for priority, category, complaint status, and tags.\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: \"Create sample user input data in JSON format\"\n",
    "# Create a sample user input as a JSON string\n",
    "user_input_json = '''{\n",
    "    \"name\": \"Ula Dobra\",\n",
    "    \"email\": \"ula.dobra@podlasem.com\",\n",
    "    \"query\": \"I would like to know the status of my order.\",\n",
    "    \"order_id\": 87647,\n",
    "    \"purchase_date\": \"2025-01-01\"\n",
    "}'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0dd2e",
   "metadata": {},
   "source": [
    "I'll use the Pydantic UserInput model to validate the user input JSON data. Validated data should be returned if there are no errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068884f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input:\n",
      "name='Ula Dobra' email='ula.dobra@podlasem.com' query='I would like to know the status of my order.' order_id=87647 purchase_date=datetime.date(2025, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: \"Use the Pydantic model to validate JSON user input\"\n",
    "#Validate the user input against the UserInput model using the model_validate_json method\n",
    "user_input = UserInput.model_validate_json(user_input_json)\n",
    "print(\"User Input:\")\n",
    "print(user_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc43b47",
   "metadata": {},
   "source": [
    "When using this method, I'll rely on [Instructor](https://python.useinstructor.com/) to pass the JSON schema of the Pydantic model in the API call. \n",
    "\n",
    "I'll first create prompt for LLM to analyze customer query and provide structured response. It doesn't include a mention of the Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72058ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-summary: \"Code to create prompt\"\n",
    "#No mention of the desired data structure in the prompt. Instructor will handle that.\n",
    "prompt = (\n",
    "    f\"Analyze the following customer query {user_input} \"\n",
    "    f\"and provide a structured response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73cb07",
   "metadata": {},
   "source": [
    "I'll then create an Anthropic client using Instructor and pass the Pydantic model as the 'response_model' parameter in the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "31f7f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use Anthropic with Instructor to get structured output (Instructor will work with OpenAI, Grok, Gemini and others as well)\n",
    "anthropic_client = instructor.from_anthropic(\n",
    "    anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    ")\n",
    "\n",
    "response = anthropic_client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",  \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    response_model=CustomerQuery  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6859d",
   "metadata": {},
   "source": [
    "This should return a valid response - as an instance of the CustomerQuery Pydantic model! üëç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f570a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Ula Dobra' email='ula.dobra@podlasem.com' query='I would like to know the status of my order.' order_id=87647 purchase_date=datetime.date(2025, 1, 1) priority='medium' category='information_request' is_complaint=False tags=['order status', 'inquiry']\n",
      "<class '__main__.CustomerQuery'>\n",
      "{\n",
      "  \"name\": \"Ula Dobra\",\n",
      "  \"email\": \"ula.dobra@podlasem.com\",\n",
      "  \"query\": \"I would like to know the status of my order.\",\n",
      "  \"order_id\": 87647,\n",
      "  \"purchase_date\": \"2025-01-01\",\n",
      "  \"priority\": \"medium\",\n",
      "  \"category\": \"information_request\",\n",
      "  \"is_complaint\": false,\n",
      "  \"tags\": [\n",
      "    \"order status\",\n",
      "    \"inquiry\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response)\n",
    "# Inspect the returned structured data in JSON format\n",
    "print(type(response))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6596d94",
   "metadata": {},
   "source": [
    "## Testing OpenAI beta API which accepts a 'response_format' argument "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f86ca3",
   "metadata": {},
   "source": [
    "Turns out that OpenAI has a version of their API that also accepts a 'response_format' argument that is a Pydantic model. No need to use Instructor in this case. Turns out other LLM providers are starting to incorporate Pydantic models in a similar way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9598f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\"name\":\"Ula Dobra\",\"email\":\"ula.dobra@podlasem.com\",\"query\":\"I would like to know the status of my order.\",\"order_id\":87647,\"purchase_date\":\"2025-01-01\",\"priority\":\"medium\",\"category\":\"information_request\",\"is_complaint\":false,\"tags\":[\"order_status\",\"customer_service\"]}\n"
     ]
    }
   ],
   "source": [
    "#| code-summary: \"Use OpenAI's API with Pydantic model for structured response\"\n",
    "# Initialize OpenAI client and call passing CustomerQuery in your API call\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    #They call the below 'constrained generation'\n",
    "    response_format=CustomerQuery\n",
    ")\n",
    "response_content = response.choices[0].message.content\n",
    "print(type(response_content))\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a58e85",
   "metadata": {},
   "source": [
    "## Testing Pydantic AI framework with Google Gemini\n",
    "\n",
    "[Pydantic AI](https://ai.pydantic.dev/#why-use-pydantic-ai) provides a nice wrapper for working with multiple LLMs. A Pydantic model can be passed as the 'output_type' argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ca50a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the Pydantic AI package for defining an agent and getting a structured response\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "agent = Agent(\n",
    "    # The model can be changed to \"gpt-4o\" or \"gpt-4o-mini\" for OpenAI models and others as well\n",
    "    model=\"openai:gpt-4o\",\n",
    "    # model=\"google-gla:gemini-2.0-flash\",\n",
    "    output_type=CustomerQuery,\n",
    ")\n",
    "\n",
    "response = agent.run_sync(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9a195",
   "metadata": {},
   "source": [
    "And we get a valid response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3841af34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentRunResult(output=CustomerQuery(name='Ula Dobra', email='ula.dobra@podlasem.com', query='I would like to know the status of my order.', order_id=87647, purchase_date=datetime.date(2025, 1, 1), priority='medium', category='information_request', is_complaint=False, tags=['order_status', 'information', 'customer_query']))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38678132",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this article, we've explored how Pydantic models can be seamlessly integrated into LLM API calls for robust data validation and structured responses. By leveraging libraries like Instructor, OpenAI's beta API, and Pydantic AI, developers can ensure consistent output formats and simplify downstream processing. As LLM providers continue to adopt Pydantic support, building reliable, type-safe AI applications becomes more accessible and efficient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
